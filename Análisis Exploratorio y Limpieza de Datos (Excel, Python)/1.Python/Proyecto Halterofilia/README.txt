Resolución de Consultas mediante Análisis de Datos y Web Scraping – Proyecto en Python Halterofilia

1. Descripción General

¡Hola!  
En este proyecto busco poner a prueba mis capacidades en Python resolviendo una serie de preguntas y consultas a partir de diferentes fuentes de datos.  
El objetivo principal es realizar un proceso completo de extracción, transformación, análisis y visualización de información, mostrando mis habilidades tanto en el manejo de datos estructurados como en la obtención de información mediante Web Scraping.  

El archivo se encuentra dividido en dos fases:  

- Una primera, en la que trabajo con datos cargados directamente.  
- Una segunda, en la que aplico técnicas de Web Scraping para obtener, limpiar y analizar información actualizada.  

En todo el proceso incluyo comentarios detallados dentro de cada bloque de código, explicando los pasos y decisiones que tomo para garantizar la claridad del flujo analítico.

---

2. Estructura del Notebook

1. Parte I – Análisis de Datos Existentes  

En esta primera fase realizo el procesamiento y análisis de los datos cargados localmente.  
Las etapas incluidas son:  

- Importación de librerías necesarias para el análisis.  
- Carga y exploración inicial de los datos para conocer su estructura y calidad.  
- Unificación de información de los años 2019 y 2020 en un único DataFrame.  
- Transformación de datos, incluyendo:  
  - Creación de nuevas columnas.  
  - Filtrado de información relevante.  
  - Conversión de tipos de datos (por ejemplo, transformar categorías a tipo int).  
  - Reordenación de columnas según la estructura deseada.  
  - Aplicación de replace para eliminar o corregir valores innecesarios que dificulten el análisis.  
  - Visualización de resultados mediante distintas gráficas para representar los datos procesados.  
- Resolución de consultas planteadas a partir de los datos disponibles.

---

2. Parte II – Análisis mediante Web Scraping  

En esta segunda fase realizo un flujo de trabajo similar al anterior, pero obteniendo los datos a través de Web Scraping.  
Las etapas incluidas son:  

- Importación de librerías especializadas para la extracción de datos web.  
- Obtención e importación de la información directamente desde fuentes en línea.  
- Exploración y análisis inicial del dataset extraído.  
- Creación de un DataFrame único con los datos recopilados desde 2019 hasta 2024.  
- Transformación y limpieza de los datos, repitiendo los pasos de normalización, creación de columnas, filtrado y reordenación.  
- Resolución de nuevas consultas basadas en la información extraída, diferenciadas de las de la primera fase.  

---

3. Flujo de Trabajo del Proyecto

1. Carga e inspección inicial de los datos.  
2. Limpieza, transformación y consolidación de la información.  
3. Creación de DataFrames únicos por fase de análisis.  
4. Análisis visual y resolución de consultas.  
5. Aplicación de Web Scraping para ampliar el análisis con datos más recientes.  
6. Presentación de resultados e interpretación final.

---

4. Tecnologías y Librerías Utilizadas

Python

Librerías principales: 
- pandas  
- numpy  
- matplotlib  
- seaborn  
- requests  
- BeautifulSoup  

---

5. Habilidades Demostradas

- Limpieza, transformación y estructuración de datos.  
- Creación y manipulación de DataFrames con pandas.  
- Análisis exploratorio (EDA) con visualizaciones personalizadas.  
- Automatización del proceso de extracción de datos mediante Web Scraping.  
- Resolución de consultas a través de análisis interpretativo.  
- Comunicación clara del flujo analítico dentro del código.

---

6. Autor

**Javier Piña Munera** 